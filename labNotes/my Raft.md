[分布式系统中的网络模型和故障模型](https://danielw.cn/network-failure-models)
[非对称网络分区](https://link.zhihu.com/?target=https%3A//github.com/baidu/braft/blob/master/docs/cn/raft_protocol.md%23symmetric-network-partitioning)

这里记录的是Raft作者博士论文里提到的一些优化, 以及个人在写实验时收集到的一些问题和针对该问题做的思考.

# 问题一: 网络分区导致的脑裂

这延续了*Raft*使用投票的方式解决**脑裂**这一个事实, 以一个5节点的集群为例子, 假设这5个节点命令如下, 括号内是它当前的状态: 

- 领导人: `A(L,1)`
- 追随者: `B(F,1)`, `C(F,1)`, `D(F,1)`, `E(F,1)`

某个时刻, 发生了网络分区的故障, 使得集群划分为如下的分区, 不同分区的服务器不能互相通信.

- 分区1: `A(L,1)`, `B(F,1)`, `C(F,1)`
- 分区2: `D(F,1)`, `E(F,1)`

得益于领导人的选拔机制, 分区2中的两个服务器即使在选举超时后发起一轮投票也无法上任领导人.  但这只是一个很朴素的网络分区故障, 接着看另一个分区情况:

- 分区1: `A(L,1)`, `B(F,1)`            ->`A(L,1)`, `B(F,1)` 
- 分区2: `C(F,1)`, `D(F,1)`, `E(F,1)`  ->`C(L,2)`, `D(F,2)`, `E(F,2)`

如果是领导人被割裂到了拥有较少服务器的分区, 那么另一个分区因拥有较多服务器, 所以会在新的一轮投票中产生新的领导人, 这个时候就发生了脑裂的问题---**分区1,2都有各自的领导人**

在实验的测试代码`cfg.one(...)`中我们可以看到对于客户端发送的请求, 采取的是轮询的方式找到领导人, 虽然在此次实验中我们提供给客户端的接口`Start(command interface{})`明确地注释了不保证该请求一定被提交和应用.  因为在测试代码中我们可以选择`cfg.one(...retry=true)`这种方式, 即一段时间内未观察到该请求被应用则接着上一次发往服务器的顺序往下轮询---直到超过设置的时间或发往了真正有用的领导人, 也就是分区2的`C(L,2)`.

***笔者想到的解决方案***

1. 租约
2. 间隔某几次心跳包就做一次虚假投票

# 问题二: 网络分区导致任期快速增长(对应论文9.6)

这个问题其实笔者在查日志的时候发现了, 但是当时并没有把它认定是一个很严重的问题( *毕竟是在这种实验环境下,以给出的测试为参考, 对*Raft*的实现没有那么严苛* ), 在*Raft*大论文里面既然作者提到了, 那我便列在这里了.

仍然是网络分区这个故障, 使我们得到以下的集群划分状况:

- 分区1: `A(L,1)`, `B(F,1)`, `C(F,1)`
- 分区2: `D(F,1)`, `E(F,1)`  ->. . . . . .->`D(F,10)`, `E(F,10)`

分区2的两个服务器既无法收到领导人的心跳消息, 也无法获得大多数服务器投票自己上任, 导致了其不停地发起选举, 增加任期, 一旦网络的故障修复, 领导人`A(L,1)`就会立刻下台, 重新选举.

硬要找出点什么影响的话, 我想就是: `分区2的服务器浪费了不必要的网络资源`, `网络修复后扰乱了一次领导人身份`, `任期数过大`.

***Raft作者给出的解决方案***

# 问题三: 非对称的网络分区导致集群领导人反复下台

**这个问题可以在Braft的文档里找到, 更完整的内容还请阅读文档**
[非对称网络分区](https://link.zhihu.com/?target=https%3A//github.com/baidu/braft/blob/master/docs/cn/raft_protocol.md%23symmetric-network-partitioning)

我们思考网络分区导致的故障时, 没有考虑过某一个服务器属于多个分区的情况:

- 分区1: `S1(L,1)`, `S3(F,1)`
- 分区2: `S2(F,1)`, `S3(F,1)`

这里的问题是, `S1`无法收到领导人的心跳, 自己不停地增加任期发起选举导致`S3`的任期也不断增加, 使得领导人下台, 如果下一次选出来的领导人还是`S2`, 那么这个问题还会持续发生.

你可能会想, 如果采纳了问题二的解决方案*PreVote*, 不就是可以避免掉`S1`不断自增任期发起选举吗? 

[这里](https://www.zhihu.com/question/483967518)答主给出了一个分区的情况(借鉴一下答主的图):

![pic](/6.5840-24Spring/pic/不对称分区的故障.webp)

很庆幸, 如果我们解决了问题一, 那么这里离群的领导人`4`就会下台. 不过在思考这个问题的时候, 又引发了对*PreVote*细节的思考, 以这里答主的回复来看, *PreVote*只会被同样选举超时的服务器同意, 这是否是个不必要的条件? 把*PreVote*单纯的视为一个自身服务器网络状况的检查是否更好?

# 问题四: raft是否需要候选人处理同一任期内重复的投票返回结果

由于我们需要保证rpc的幂等性, 当服务器收到投票请求时会检查`rf.VotedFor == args.CandidateId`, 因此确保因网络故障导致的重发投票请求服务器会返回相同的结果.

但这也会打破raft对投票的规定, 每一个服务器在同一个任期内只允许投票一次. 目前我未发现这个错误对整个集群的正确性有何影响. 如果需要处理它, 也仅仅需要在发起选举时记录下每张得票的来源, 滤掉重复的即可.

# DEBUG_printf策略

先列举一下我们用到的函数(线程)

1. 每个服务器开了三个线程, 分别用于rpc收发信息, 心跳机制, 超时选举
2. *leader*发送心跳消息的函数`sendHeartbeat()`, 其他服务器接收并处理心跳消息的函数`Heartbeat()`
3. *candidate*发送选举消息的函数`sendRequestVote()`, 其他服务器进行投票的函数`RequestVote()`

调试详细的格式按照:`p[i]-t-TFZ: xxxx`, `p[i]`是事件发起者的服务器标识, `t`是其任期, `TFZ`则是自己实现的从该服务器创建时就开始计时的计时器, 后面的`xxxx`是具体要展示的信息, 我们有以下几种信息按规定输出:

**对每一轮选举的调试信息**: 发起选举的*candidate*需要展示`Vote Start`和`Vote End`这两个信息, 并且在这一轮投票结束后输出其得票数, 投票人也需要展示自己投给的目标, 后续可能需要有拒绝投票的理由, `%s`表示的是服务器的状态: `C`, `L`, `F`

```go
if DEBUG_Vote{
	fmt.Printf("p%d(%s)-%d-%10v: Vote Start (t%d)\n")
}

if DEBUG_Vote{
	fmt.Printf("p%d(%s)-%d-%10v: Vote End with %dvotes (t%d)\n")
}


if DEBUG_Vote{
	fmt.Printf("p%d(%s)-%d-%10v: Voted p%d->p%d\n")
}

if DEBUG_Vote{
	fmt.Printf("p%d(%s)-%d-%10v: Refuse, had vote p%d->p%d\n")
}
```

**对心跳消息的调试信息**: 发出心跳消息的只能是leader, 所以只需要按常规信息输出即可

```go
if DEBUG_Heartbeat{
	fmt.Printf("p%d(%s)-%d-%10v: !!!Heartbeat!!!\n")
}

if DEBUG_Heartbeat{
	fmt.Printf("p%d(%s)-%d-%10v: p%d(L)->p%d(F) beat!!!\n")
}

```